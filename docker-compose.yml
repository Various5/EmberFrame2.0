# Production Docker Compose Configuration for EmberFrame V2
# This file sets up a complete production environment with all services

version: '3.8'

services:
  # Main application
  app:
    build:
      context: emberframe-v2
      dockerfile: Dockerfile.prod
      args:
        - BUILD_ENV=production
    container_name: emberframe_app
    restart: unless-stopped
    ports:
      - "8000:8000"
    environment:
      - APP_NAME=EmberFrame V2
      - DEBUG=false
      - SECRET_KEY=${SECRET_KEY}
      - DATABASE_URL=postgresql://${POSTGRES_USER}:${POSTGRES_PASSWORD}@db:5432/${POSTGRES_DB}
      - REDIS_URL=redis://redis:6379/0
      - ALLOWED_HOSTS=["${DOMAIN}", "www.${DOMAIN}", "localhost"]
      - SESSION_EXPIRE=86400
      - TOKEN_EXPIRE_HOURS=24
      - UPLOAD_DIR=/app/uploads
      - MAX_FILE_SIZE=104857600
      - DEFAULT_ADMIN_USERNAME=${ADMIN_USERNAME}
      - DEFAULT_ADMIN_PASSWORD=${ADMIN_PASSWORD}
      # Email settings
      - SMTP_HOST=${SMTP_HOST}
      - SMTP_PORT=${SMTP_PORT}
      - SMTP_USER=${SMTP_USER}
      - SMTP_PASSWORD=${SMTP_PASSWORD}
      - EMAIL_FROM=${EMAIL_FROM}
      # External services
      - AWS_ACCESS_KEY_ID=${AWS_ACCESS_KEY_ID}
      - AWS_SECRET_ACCESS_KEY=${AWS_SECRET_ACCESS_KEY}
      - AWS_REGION=${AWS_REGION}
      - S3_BUCKET=${S3_BUCKET}
      - SENTRY_DSN=${SENTRY_DSN}
    volumes:
      - app_uploads:/app/uploads
      - app_logs:/app/logs
      - ./ssl:/app/ssl:ro
    depends_on:
      - db
      - redis
    networks:
      - emberframe_network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

  # PostgreSQL Database
  db:
    image: postgres:15-alpine
    container_name: emberframe_db
    restart: unless-stopped
    environment:
      - POSTGRES_DB=${POSTGRES_DB}
      - POSTGRES_USER=${POSTGRES_USER}
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD}
      - POSTGRES_INITDB_ARGS=--auth-host=scram-sha-256
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./backups:/backups
      - ./scripts/db-init:/docker-entrypoint-initdb.d
    ports:
      - "127.0.0.1:5432:5432"  # Only expose to localhost
    networks:
      - emberframe_network
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER} -d ${POSTGRES_DB}"]
      interval: 10s
      timeout: 5s
      retries: 5

  # Redis Cache and Message Broker
  redis:
    image: redis:7-alpine
    container_name: emberframe_redis
    restart: unless-stopped
    command: redis-server --appendonly yes --requirepass ${REDIS_PASSWORD}
    environment:
      - REDIS_PASSWORD=${REDIS_PASSWORD}
    volumes:
      - redis_data:/data
      - ./config/redis.conf:/usr/local/etc/redis/redis.conf
    ports:
      - "127.0.0.1:6379:6379"  # Only expose to localhost
    networks:
      - emberframe_network
    healthcheck:
      test: ["CMD", "redis-cli", "--raw", "incr", "ping"]
      interval: 10s
      timeout: 3s
      retries: 5

  # Celery Worker
  celery:
    build:
      context: emberframe-v2
      dockerfile: Dockerfile.prod
    container_name: emberframe_celery
    restart: unless-stopped
    command: celery -A app.tasks worker --loglevel=info --concurrency=4
    environment:
      - APP_NAME=EmberFrame V2
      - DEBUG=false
      - SECRET_KEY=${SECRET_KEY}
      - DATABASE_URL=postgresql://${POSTGRES_USER}:${POSTGRES_PASSWORD}@db:5432/${POSTGRES_DB}
      - REDIS_URL=redis://redis:6379/0
      - UPLOAD_DIR=/app/uploads
    volumes:
      - app_uploads:/app/uploads
      - app_logs:/app/logs
    depends_on:
      - db
      - redis
    networks:
      - emberframe_network
    healthcheck:
      test: ["CMD", "celery", "-A", "app.tasks", "inspect", "ping"]
      interval: 30s
      timeout: 10s
      retries: 3

  # Celery Beat (Scheduler)
  celery-beat:
    build:
      context: emberframe-v2
      dockerfile: Dockerfile.prod
    container_name: emberframe_celery_beat
    restart: unless-stopped
    command: celery -A app.tasks beat --loglevel=info
    environment:
      - APP_NAME=EmberFrame V2
      - DEBUG=false
      - SECRET_KEY=${SECRET_KEY}
      - DATABASE_URL=postgresql://${POSTGRES_USER}:${POSTGRES_PASSWORD}@db:5432/${POSTGRES_DB}
      - REDIS_URL=redis://redis:6379/0
    volumes:
      - app_logs:/app/logs
    depends_on:
      - db
      - redis
    networks:
      - emberframe_network

  # Nginx Reverse Proxy
  nginx:
    image: nginx:alpine
    container_name: emberframe_nginx
    restart: unless-stopped
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./config/nginx/nginx.conf:/etc/nginx/nginx.conf:ro
      - ./config/nginx/sites:/etc/nginx/sites-available:ro
      - ./ssl:/etc/nginx/ssl:ro
      - app_uploads:/var/www/uploads:ro
      - ./static:/var/www/static:ro
    depends_on:
      - app
    networks:
      - emberframe_network
    healthcheck:
      test: ["CMD", "wget", "--quiet", "--tries=1", "--spider", "http://localhost/health"]
      interval: 30s
      timeout: 10s
      retries: 3

  # Monitoring with Prometheus
  prometheus:
    image: prom/prometheus:latest
    container_name: emberframe_prometheus
    restart: unless-stopped
    ports:
      - "127.0.0.1:9090:9090"
    volumes:
      - ./config/prometheus/prometheus.yml:/etc/prometheus/prometheus.yml:ro
      - prometheus_data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/usr/share/prometheus/console_libraries'
      - '--web.console.templates=/usr/share/prometheus/consoles'
      - '--storage.tsdb.retention.time=200h'
      - '--web.enable-lifecycle'
    networks:
      - emberframe_network

  # Monitoring with Grafana
  grafana:
    image: grafana/grafana:latest
    container_name: emberframe_grafana
    restart: unless-stopped
    ports:
      - "127.0.0.1:3000:3000"
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=${GRAFANA_PASSWORD}
      - GF_INSTALL_PLUGINS=grafana-clock-panel,grafana-simple-json-datasource
    volumes:
      - grafana_data:/var/lib/grafana
      - ./config/grafana/provisioning:/etc/grafana/provisioning
    networks:
      - emberframe_network

  # Log Management with Loki
  loki:
    image: grafana/loki:latest
    container_name: emberframe_loki
    restart: unless-stopped
    ports:
      - "127.0.0.1:3100:3100"
    volumes:
      - ./config/loki/loki.yml:/etc/loki/local-config.yaml
      - loki_data:/loki
    command: -config.file=/etc/loki/local-config.yaml
    networks:
      - emberframe_network

  # Log Collector with Promtail
  promtail:
    image: grafana/promtail:latest
    container_name: emberframe_promtail
    restart: unless-stopped
    volumes:
      - ./config/promtail/promtail.yml:/etc/promtail/config.yml
      - app_logs:/var/log/emberframe
      - /var/lib/docker/containers:/var/lib/docker/containers:ro
      - /var/run/docker.sock:/var/run/docker.sock
    command: -config.file=/etc/promtail/config.yml
    networks:
      - emberframe_network

  # Backup Service
  backup:
    image: alpine:latest
    container_name: emberframe_backup
    restart: "no"
    environment:
      - POSTGRES_DB=${POSTGRES_DB}
      - POSTGRES_USER=${POSTGRES_USER}
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD}
      - AWS_ACCESS_KEY_ID=${AWS_ACCESS_KEY_ID}
      - AWS_SECRET_ACCESS_KEY=${AWS_SECRET_ACCESS_KEY}
      - S3_BACKUP_BUCKET=${S3_BACKUP_BUCKET}
    volumes:
      - ./scripts/backup.sh:/backup.sh:ro
      - ./backups:/backups
      - app_uploads:/uploads:ro
    command: |
      sh -c "
        apk add --no-cache postgresql-client aws-cli
        chmod +x /backup.sh
        crond -f
      "
    networks:
      - emberframe_network

# Networks
networks:
  emberframe_network:
    driver: bridge
    ipam:
      config:
        - subnet: 172.20.0.0/16

# Volumes
volumes:
  postgres_data:
    driver: local
  redis_data:
    driver: local
  app_uploads:
    driver: local
  app_logs:
    driver: local
  prometheus_data:
    driver: local
  grafana_data:
    driver: local
  loki_data:
    driver: local

---
# Dockerfile.prod - Production Dockerfile
FROM python:3.11-slim as builder

# Set environment variables
ENV PYTHONDONTWRITEBYTECODE=1
ENV PYTHONUNBUFFERED=1
ENV PIP_NO_CACHE_DIR=1
ENV PIP_DISABLE_PIP_VERSION_CHECK=1

# Install system dependencies
RUN apt-get update && apt-get install -y \
    gcc \
    g++ \
    libpq-dev \
    libmagic1 \
    curl \
    && rm -rf /var/lib/apt/lists/*

# Create and set work directory
WORKDIR /app

# Install Python dependencies
COPY requirements/production.txt requirements.txt
RUN pip install --no-cache-dir -r requirements.txt

# Production stage
FROM python:3.11-slim

# Set environment variables
ENV PYTHONDONTWRITEBYTECODE=1
ENV PYTHONUNBUFFERED=1
ENV APP_ENV=production

# Install runtime dependencies
RUN apt-get update && apt-get install -y \
    libpq5 \
    libmagic1 \
    curl \
    && rm -rf /var/lib/apt/lists/*

# Create app user
RUN groupadd -r app && useradd -r -g app app

# Set work directory
WORKDIR /app

# Copy Python dependencies from builder stage
COPY --from=builder /usr/local/lib/python3.11/site-packages /usr/local/lib/python3.11/site-packages
COPY --from=builder /usr/local/bin /usr/local/bin

# Copy application code
COPY . .

# Create necessary directories
RUN mkdir -p uploads logs static && \
    chown -R app:app /app

# Switch to app user
USER app

# Expose port
EXPOSE 8000

# Health check
HEALTHCHECK --interval=30s --timeout=30s --start-period=5s --retries=3 \
    CMD curl -f http://localhost:8000/health || exit 1

# Run application
CMD ["gunicorn", "main:app", "-c", "gunicorn.conf.py"]

---
# .env.production - Production environment template
# Copy this to .env and customize for your environment

# Basic Configuration
APP_NAME=EmberFrame V2
DEBUG=false
SECRET_KEY=your-super-secret-key-change-this-in-production
DOMAIN=your-domain.com

# Database
POSTGRES_DB=emberframe_prod
POSTGRES_USER=emberframe
POSTGRES_PASSWORD=your-secure-database-password

# Redis
REDIS_PASSWORD=your-secure-redis-password

# Admin User
ADMIN_USERNAME=admin
ADMIN_PASSWORD=change-this-secure-admin-password

# Email Configuration
SMTP_HOST=smtp.your-email-provider.com
SMTP_PORT=587
SMTP_USER=your-email@your-domain.com
SMTP_PASSWORD=your-email-password
EMAIL_FROM=noreply@your-domain.com

# AWS S3 (Optional)
AWS_ACCESS_KEY_ID=your-aws-access-key
AWS_SECRET_ACCESS_KEY=your-aws-secret-key
AWS_REGION=us-east-1
S3_BUCKET=emberframe-files
S3_BACKUP_BUCKET=emberframe-backups

# Monitoring
SENTRY_DSN=your-sentry-dsn
GRAFANA_PASSWORD=your-grafana-password

# SSL/TLS
SSL_CERT_PATH=/app/ssl/cert.pem
SSL_KEY_PATH=/app/ssl/key.pem

---
# config/nginx/nginx.conf - Nginx configuration
user nginx;
worker_processes auto;
error_log /var/log/nginx/error.log notice;
pid /var/run/nginx.pid;

events {
    worker_connections 1024;
    use epoll;
    multi_accept on;
}

http {
    include /etc/nginx/mime.types;
    default_type application/octet-stream;

    # Logging
    log_format main '$remote_addr - $remote_user [$time_local] "$request" '
                    '$status $body_bytes_sent "$http_referer" '
                    '"$http_user_agent" "$http_x_forwarded_for"';
    
    access_log /var/log/nginx/access.log main;

    # Performance
    sendfile on;
    tcp_nopush on;
    tcp_nodelay on;
    keepalive_timeout 65;
    types_hash_max_size 2048;
    server_tokens off;

    # Gzip compression
    gzip on;
    gzip_vary on;
    gzip_min_length 10240;
    gzip_proxied expired no-cache no-store private must-revalidate auth;
    gzip_types
        text/plain
        text/css
        text/xml
        text/javascript
        application/javascript
        application/xml+rss
        application/json;

    # Rate limiting
    limit_req_zone $binary_remote_addr zone=api:10m rate=10r/s;
    limit_req_zone $binary_remote_addr zone=login:10m rate=1r/s;

    # Upstream
    upstream emberframe_app {
        server app:8000;
        keepalive 32;
    }

    # HTTP to HTTPS redirect
    server {
        listen 80;
        server_name _;
        return 301 https://$host$request_uri;
    }

    # Main HTTPS server
    server {
        listen 443 ssl http2;
        server_name your-domain.com www.your-domain.com;

        # SSL Configuration
        ssl_certificate /etc/nginx/ssl/cert.pem;
        ssl_certificate_key /etc/nginx/ssl/key.pem;
        ssl_session_cache shared:SSL:10m;
        ssl_session_timeout 10m;
        ssl_ciphers ECDHE-RSA-AES128-GCM-SHA256:ECDHE-RSA-AES256-GCM-SHA384;
        ssl_protocols TLSv1.2 TLSv1.3;
        ssl_prefer_server_ciphers off;

        # Security headers
        add_header X-Frame-Options "SAMEORIGIN" always;
        add_header X-XSS-Protection "1; mode=block" always;
        add_header X-Content-Type-Options "nosniff" always;
        add_header Referrer-Policy "no-referrer-when-downgrade" always;
        add_header Content-Security-Policy "default-src 'self' http: https: data: blob: 'unsafe-inline'" always;

        # File upload size
        client_max_body_size 100M;

        # Static files
        location /static/ {
            alias /var/www/static/;
            expires 1y;
            add_header Cache-Control "public, immutable";
        }

        # User uploads
        location /uploads/ {
            alias /var/www/uploads/;
            expires 1M;
            add_header Cache-Control "public";
        }

        # API endpoints with rate limiting
        location /api/ {
            limit_req zone=api burst=20 nodelay;
            proxy_pass http://emberframe_app;
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header X-Forwarded-Proto $scheme;
        }

        # Login endpoint with stricter rate limiting
        location /api/auth/login {
            limit_req zone=login burst=3 nodelay;
            proxy_pass http://emberframe_app;
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header X-Forwarded-Proto $scheme;
        }

        # WebSocket support
        location /ws/ {
            proxy_pass http://emberframe_app;
            proxy_http_version 1.1;
            proxy_set_header Upgrade $http_upgrade;
            proxy_set_header Connection "upgrade";
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header X-Forwarded-Proto $scheme;
        }

        # Main application
        location / {
            proxy_pass http://emberframe_app;
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header X-Forwarded-Proto $scheme;
        }
    }
}

---
# scripts/deploy.sh - Deployment script
#!/bin/bash

set -e

echo "üöÄ Deploying EmberFrame V2 to production..."

# Configuration
COMPOSE_FILE="docker-compose.prod.yml"
ENV_FILE=".env"

# Check if environment file exists
if [ ! -f "$ENV_FILE" ]; then
    echo "‚ùå Environment file $ENV_FILE not found!"
    echo "Please copy .env.production to .env and configure it."
    exit 1
fi

# Check if SSL certificates exist
if [ ! -f "ssl/cert.pem" ] || [ ! -f "ssl/key.pem" ]; then
    echo "‚ö†Ô∏è  SSL certificates not found in ssl/ directory"
    echo "Please add your SSL certificates or the deployment will use self-signed certificates"
fi

# Pull latest images
echo "üì¶ Pulling latest Docker images..."
docker-compose -f $COMPOSE_FILE pull

# Build application image
echo "üî® Building application image..."
docker-compose -f $COMPOSE_FILE build --no-cache app

# Stop existing containers
echo "üõë Stopping existing containers..."
docker-compose -f $COMPOSE_FILE down

# Start services
echo "üöÄ Starting services..."
docker-compose -f $COMPOSE_FILE up -d

# Wait for database to be ready
echo "‚è≥ Waiting for database to be ready..."
sleep 10

# Initialize database
echo "üóÑÔ∏è  Initializing database..."
docker-compose -f $COMPOSE_FILE exec -T app python scripts/init_db.py init

# Check health
echo "üîç Checking service health..."
sleep 30

# Verify all services are running
SERVICES=(app db redis nginx celery)
for service in "${SERVICES[@]}"; do
    if docker-compose -f $COMPOSE_FILE ps | grep -q "${service}.*Up"; then
        echo "‚úÖ $service is running"
    else
        echo "‚ùå $service is not running"
        docker-compose -f $COMPOSE_FILE logs $service
        exit 1
    fi
done

echo "üéâ Deployment completed successfully!"
echo ""
echo "üåê Application URL: https://$(grep DOMAIN $ENV_FILE | cut -d'=' -f2)"
echo "üìä Monitoring: https://$(grep DOMAIN $ENV_FILE | cut -d'=' -f2):3000"
echo "üìà Metrics: https://$(grep DOMAIN $ENV_FILE | cut -d'=' -f2):9090"
echo ""
echo "üîß Useful commands:"
echo "  View logs: docker-compose -f $COMPOSE_FILE logs -f"
echo "  Restart service: docker-compose -f $COMPOSE_FILE restart <service>"
echo "  Scale workers: docker-compose -f $COMPOSE_FILE up -d --scale celery=3"